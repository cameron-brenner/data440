# -*- coding: utf-8 -*-
"""hw3prob1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NDYNwnP1qZDthWPKB9sLFBscsqhwNOMN
"""

import numpy as np
from matplotlib import pyplot as plt
from sklearn.neighbors import KNeighborsRegressor
from sklearn.model_selection import KFold
from sklearn.metrics import mean_squared_error

def genDataSet(N):
    X = np.random.normal(0, 1, N)
    ytrue = (np.cos(X) + 2) / (np.cos(X * 1.4) + 2)
    noise = np.random.normal(0, 0.2, N)
    y = ytrue + noise
    return X, y, ytrue

X, y, ytrue = genDataSet(1000)
plt.plot(X,y,'.')
plt.plot(X,ytrue,'rx')
plt.show()


kf = KFold(n_splits=10)
x, y, ytrue = genDataSet(1000)
X = np.array([x,y]).T
kf.get_n_splits(X)

msek = {}
#plt.figure(figsize=(10,10))
bestk = 0
bestmse = 100000
for k in np.arange(1,2*np.floor(((len(ytrue)*0.9)+1)/2),2):
  print(k)
  mse = []
  for train_index, test_index in kf.split(X):
    X_train, X_test =     X[train_index],     X[test_index]
    y_train, y_test = ytrue[train_index], ytrue[test_index]


    neigh = KNeighborsRegressor(n_neighbors=int(k))
    neigh.fit(X_train, y_train)
    predictions = neigh.predict(X_test)

    mse.append(mean_squared_error(y_test, predictions))

  print(np.mean(mse))
  msek[k] = np.mean(mse)
  if bestmse > msek[k]:
    bestmse = msek[k]
    bestk = k
    print(bestk,bestmse)

bestkall.append(bestk)
#plt.plot(k,msek[k],'r.')
  
#plt.show()
print(bestkall)